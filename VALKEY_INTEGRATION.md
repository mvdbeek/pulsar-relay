# Valkey Storage Backend Integration

This document describes the Valkey storage backend implementation for the Pulsar Relay.

## Overview

The Valkey storage backend provides persistent message storage using Valkey Streams. It offers:

- **Persistent Storage**: Messages survive server restarts with AOF/RDB persistence
- **High Performance**: Leverages Valkey Streams for efficient message queueing
- **Automatic Trimming**: Configurable message retention policies
- **Scalability**: Can handle millions of messages with efficient memory usage

## Architecture

### Storage Structure

The Valkey backend uses the following key patterns:

- **Stream Keys**: `stream:topic:{topic_name}` - Stores messages as Valkey Streams
- **Metadata Keys**: `meta:topic:{topic_name}` - Stores topic metadata (reserved for future use)

### Message Format

Each message in a Valkey Stream contains:

```json
{
  "message_id": "msg_abc123",
  "payload": "{\"key\":\"value\"}",  // JSON-encoded payload
  "timestamp": "2025-01-01T12:00:00",
  "metadata": "{\"source\":\"api\"}"  // Optional JSON-encoded metadata
}
```

The stream entry ID (e.g., `1234567890123-0`) is automatically generated by Valkey and represents the message's position in the stream.

## Configuration

### Environment Variables

```bash
# Select Valkey as the storage backend
STORAGE_BACKEND=valkey

# Valkey connection settings
VALKEY_HOST=localhost
VALKEY_PORT=6379
VALKEY_PASSWORD=          # Optional password
VALKEY_USE_TLS=false      # Enable TLS for secure connections

# Storage retention policies
PERSISTENT_TIER_RETENTION=86400      # 24 hours in seconds
MAX_MESSAGES_PER_TOPIC=1000000       # Maximum messages per topic
```

### Valkey Server Configuration

For production use, configure your Valkey server with persistence:

**valkey.conf:**
```conf
# AOF Persistence (recommended)
appendonly yes
appendfsync everysec
auto-aof-rewrite-percentage 100
auto-aof-rewrite-min-size 64mb

# RDB Snapshots (backup)
save 900 1
save 300 10
save 60 10000

# Memory Management
maxmemory 2gb
maxmemory-policy allkeys-lru

# Performance
tcp-backlog 511
timeout 0
tcp-keepalive 300
```

## Features

### 1. Persistent Message Storage

Messages are stored in Valkey Streams and persist across server restarts:

```python
await storage.save_message(
    message_id="msg_123",
    topic="orders",
    payload={"order_id": 123, "status": "pending"},
    timestamp=datetime.now(),
    metadata={"source": "api"}
)
```

### 2. Message Retrieval

Retrieve messages from a topic with pagination support:

```python
# Get first 10 messages
messages = await storage.get_messages("orders", limit=10)

# Get next 10 messages after a specific stream ID
messages = await storage.get_messages(
    "orders",
    since="1234567890123-0",
    limit=10
)
```

### 3. Automatic Stream Trimming

Streams are automatically trimmed when messages are added:

- **Approximate Trimming**: Fast, uses `XTRIM MAXLEN ~` for performance
- **Configurable Limit**: Set via `MAX_MESSAGES_PER_TOPIC`
- **Minimal Overhead**: Trimming happens asynchronously

Manual trimming is also supported:

```python
# Keep only the most recent 1000 messages
removed = await storage.trim_topic("orders", keep_count=1000)
```

### 4. Topic Statistics

Get the current message count for a topic:

```python
length = await storage.get_topic_length("orders")
print(f"Topic has {length} messages")
```

### 5. Health Monitoring

Check Valkey connection health:

```python
health = await storage.health_check()
# Returns: {
#     "status": "healthy",
#     "connected": True,
#     "host": "localhost",
#     "port": 6379,
#     "server_info": {...}
# }
```

## API Reference

### ValkeyStorage Class

```python
class ValkeyStorage(StorageBackend):
    def __init__(
        self,
        host: str = "localhost",
        port: int = 6379,
        max_messages_per_topic: int = 1000000,
        ttl_seconds: int = 3600,
        use_tls: bool = False,
    )
```

#### Methods

**async connect() -> None**
- Establishes connection to Valkey server
- Must be called before any operations

**async disconnect() -> None**
- Closes connection to Valkey server
- Should be called on application shutdown

**async save_message(...) -> None**
- Saves a message to a Valkey Stream
- Automatically trims stream if it exceeds max length

**async get_messages(...) -> List[Dict]**
- Retrieves messages from a stream
- Supports pagination with `since` parameter

**async trim_topic(topic: str, keep_count: int) -> int**
- Trims a topic to keep only recent messages
- Returns number of messages removed

**async get_topic_length(topic: str) -> int**
- Returns the current number of messages in a topic

**async health_check() -> Dict**
- Checks Valkey connection health
- Returns server info and status

**async clear() -> None**
- Deletes all streams (for testing only)
- WARNING: This is destructive!

## Usage Examples

### Starting the Server with Valkey

1. **Start Valkey server:**
```bash
docker run -d --name valkey -p 6379:6379 valkey/valkey:latest
```

2. **Configure environment:**
```bash
export STORAGE_BACKEND=valkey
export VALKEY_HOST=localhost
export VALKEY_PORT=6379
```

3. **Start the relay:**
```bash
uvicorn app.main:app --host 0.0.0.0 --port 8080
```

### Docker Compose Example

```yaml
version: '3.8'

services:
  valkey:
    image: valkey/valkey:latest
    ports:
      - "6379:6379"
    volumes:
      - ./valkey.conf:/etc/valkey/valkey.conf
      - valkey-data:/data
    command: valkey-server /etc/valkey/valkey.conf

  relay:
    build: .
    ports:
      - "8080:8080"
    environment:
      - STORAGE_BACKEND=valkey
      - VALKEY_HOST=valkey
      - VALKEY_PORT=6379
    depends_on:
      - valkey

volumes:
  valkey-data:
```

## Performance Considerations

### Benchmarks

With Valkey backend (approximate, hardware-dependent):

- **Write Throughput**: ~30K-50K messages/sec
- **Read Latency**: ~1-2ms for recent messages
- **Storage Efficiency**: ~500 bytes per message (depends on payload)
- **Stream Trimming**: <1ms for approximate trimming

### Optimization Tips

1. **Use Approximate Trimming**: Enabled by default, faster than exact trimming
2. **Batch Writes**: Use bulk message API for high-throughput scenarios
3. **Connection Pooling**: Valkey GLIDE uses connection pooling internally
4. **Monitor Memory**: Set `maxmemory` and use `allkeys-lru` eviction
5. **Enable AOF**: Use `appendfsync everysec` for balance of durability and performance

### Scaling Considerations

For high-scale deployments:

- **Horizontal Scaling**: Use Valkey Cluster for distributed storage
- **Sharding**: Distribute topics across multiple Valkey instances
- **Replication**: Use Valkey replicas for read scaling and high availability
- **Monitoring**: Track stream lengths, memory usage, and latency metrics

## Testing

### Unit Tests

Run unit tests with mocked Valkey client:

```bash
pytest tests/test_valkey_storage.py -m "not integration"
```

### Integration Tests

Run integration tests with real Valkey instance:

```bash
# Start Valkey
docker run -d --name test-valkey -p 6379:6379 valkey/valkey:latest

# Run integration tests
pytest tests/test_valkey_storage.py -m integration

# Cleanup
docker stop test-valkey && docker rm test-valkey
```

## Troubleshooting

### Connection Issues

**Problem**: `Failed to connect to Valkey`

**Solutions**:
- Check Valkey is running: `redis-cli -h localhost -p 6379 ping`
- Verify host/port configuration
- Check firewall rules
- Enable debug logging: `LOG_LEVEL=DEBUG`

### Memory Issues

**Problem**: Valkey running out of memory

**Solutions**:
- Reduce `MAX_MESSAGES_PER_TOPIC`
- Enable eviction policy: `maxmemory-policy allkeys-lru`
- Increase `maxmemory` limit
- Implement manual trimming based on time

### Performance Issues

**Problem**: Slow message writes

**Solutions**:
- Check Valkey server load
- Enable AOF `appendfsync everysec` (not `always`)
- Use bulk message API for batching
- Consider Valkey Cluster for sharding

## Migration Guide

### From Memory to Valkey

1. **Backup current data** (if needed for migration)
2. **Update configuration**:
   ```bash
   STORAGE_BACKEND=valkey
   ```
3. **Start Valkey server**
4. **Restart relay**
5. **Verify health**: `curl http://localhost:8080/health`

### From Valkey to Memory

1. **Update configuration**:
   ```bash
   STORAGE_BACKEND=memory
   ```
2. **Restart relay**
3. **Note**: Existing messages in Valkey will be inaccessible but not deleted

## Future Enhancements

Planned features for the Valkey backend:

- [ ] Consumer Groups for multi-consumer scenarios
- [ ] Message acknowledgment tracking
- [ ] TTL-based message expiration
- [ ] Topic metadata storage
- [ ] Stream compaction for historical data
- [ ] Valkey Cluster support
- [ ] Sentinel integration for HA

## Resources

- [Valkey Official Documentation](https://valkey.io/docs/)
- [Valkey Streams Guide](https://valkey.io/topics/streams-intro/)
- [Valkey GLIDE Python Client](https://github.com/valkey-io/valkey-glide)
- [Persistence Configuration](https://valkey.io/topics/persistence/)

## Support

For issues or questions:
- GitHub Issues: [pulsar-relay/issues](https://github.com/your-org/pulsar-relay/issues)
- Documentation: `README.md`, `ARCHITECTURE.md`
